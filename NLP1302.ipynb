{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re,nltk\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Reviews.csv')\n",
    "data=data.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_preprocessor(text):\n",
    "    text=re.sub('[^a-zA-Z]', \" \", str(text))\n",
    "    text=text.lower()\n",
    "    text_tokens=word_tokenize(text)\n",
    "    text_tokens_no_sw=[w for w in text_tokens if not w in sw]\n",
    "    text=TreebankWordDetokenizer().detokenize(text_tokens_no_sw)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=data['Text'].apply(word_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>483146</td>\n",
       "      <td>483147</td>\n",
       "      <td>B004OGELRY</td>\n",
       "      <td>A2O9MGVL0OMFHC</td>\n",
       "      <td>S. Dobbs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1347408000</td>\n",
       "      <td>picture of the package of the dog chew is not ...</td>\n",
       "      <td>If you open the link to the Smartbones you wil...</td>\n",
       "      <td>open link smartbones see shows picture package...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149014</td>\n",
       "      <td>149015</td>\n",
       "      <td>B004Q3LBTG</td>\n",
       "      <td>A2ROHX8KIYNRDZ</td>\n",
       "      <td>Mrs D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1315094400</td>\n",
       "      <td>LOVE the Brezza, makes my life so easy!</td>\n",
       "      <td>I knew I wanted to feed my baby homemade nutri...</td>\n",
       "      <td>knew wanted feed baby homemade nutritious meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443002</td>\n",
       "      <td>443003</td>\n",
       "      <td>B002P323DC</td>\n",
       "      <td>A1LXOYWOSPV9ZR</td>\n",
       "      <td>kerstin rubbert-slawek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1344729600</td>\n",
       "      <td>horrible</td>\n",
       "      <td>This does not tast anything like haribo from g...</td>\n",
       "      <td>tast anything like haribo germany eatable buy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129025</td>\n",
       "      <td>129026</td>\n",
       "      <td>B003FE1O3K</td>\n",
       "      <td>A1YGD23AOVZ1CJ</td>\n",
       "      <td>ZOMGPWN!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1300665600</td>\n",
       "      <td>Vitamin Sour</td>\n",
       "      <td>If you enjoy sour candy and you've never tried...</td>\n",
       "      <td>enjoy sour candy never tried sour punch brand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75540</td>\n",
       "      <td>75541</td>\n",
       "      <td>B002E0WEJ4</td>\n",
       "      <td>A3O26ZXTV454ZZ</td>\n",
       "      <td>ecooper05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1325808000</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>I sent this basket to my mother as a christmas...</td>\n",
       "      <td>sent basket mother christmas gift said fruit f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId             ProfileName  \\\n",
       "483146  483147  B004OGELRY  A2O9MGVL0OMFHC                S. Dobbs   \n",
       "149014  149015  B004Q3LBTG  A2ROHX8KIYNRDZ                   Mrs D   \n",
       "443002  443003  B002P323DC  A1LXOYWOSPV9ZR  kerstin rubbert-slawek   \n",
       "129025  129026  B003FE1O3K  A1YGD23AOVZ1CJ                ZOMGPWN!   \n",
       "75540    75541  B002E0WEJ4  A3O26ZXTV454ZZ               ecooper05   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "483146                     0                       1      1  1347408000   \n",
       "149014                     2                       2      5  1315094400   \n",
       "443002                     0                       0      1  1344729600   \n",
       "129025                     3                       3      5  1300665600   \n",
       "75540                      1                       1      5  1325808000   \n",
       "\n",
       "                                                  Summary  \\\n",
       "483146  picture of the package of the dog chew is not ...   \n",
       "149014            LOVE the Brezza, makes my life so easy!   \n",
       "443002                                           horrible   \n",
       "129025                                       Vitamin Sour   \n",
       "75540                                           Loved it!   \n",
       "\n",
       "                                                     Text  \\\n",
       "483146  If you open the link to the Smartbones you wil...   \n",
       "149014  I knew I wanted to feed my baby homemade nutri...   \n",
       "443002  This does not tast anything like haribo from g...   \n",
       "129025  If you enjoy sour candy and you've never tried...   \n",
       "75540   I sent this basket to my mother as a christmas...   \n",
       "\n",
       "                                             cleaned_text  \n",
       "483146  open link smartbones see shows picture package...  \n",
       "149014  knew wanted feed baby homemade nutritious meal...  \n",
       "443002  tast anything like haribo germany eatable buy ...  \n",
       "129025  enjoy sour candy never tried sour punch brand ...  \n",
       "75540   sent basket mother christmas gift said fruit f...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Text'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=tf_idf.fit_transform(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense=score.todense()\n",
    "dense1=dense.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dense1,columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abilities</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>absoute</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundance</th>\n",
       "      <th>...</th>\n",
       "      <th>zeisners</th>\n",
       "      <th>zero</th>\n",
       "      <th>zico</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoethout</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zua</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandoned  abilities  able  absolute  absolutely  absorb  absorbs  absoute  \\\n",
       "0        0.0        0.0   0.0       0.0         0.0     0.0      0.0      0.0   \n",
       "1        0.0        0.0   0.0       0.0         0.0     0.0      0.0      0.0   \n",
       "2        0.0        0.0   0.0       0.0         0.0     0.0      0.0      0.0   \n",
       "3        0.0        0.0   0.0       0.0         0.0     0.0      0.0      0.0   \n",
       "4        0.0        0.0   0.0       0.0         0.0     0.0      0.0      0.0   \n",
       "\n",
       "   absurd  abundance  ...  zeisners  zero  zico  zip  zoethout  zombie  zoo  \\\n",
       "0     0.0        0.0  ...       0.0   0.0   0.0  0.0       0.0     0.0  0.0   \n",
       "1     0.0        0.0  ...       0.0   0.0   0.0  0.0       0.0     0.0  0.0   \n",
       "2     0.0        0.0  ...       0.0   0.0   0.0  0.0       0.0     0.0  0.0   \n",
       "3     0.0        0.0  ...       0.0   0.0   0.0  0.0       0.0     0.0  0.0   \n",
       "4     0.0        0.0  ...       0.0   0.0   0.0  0.0       0.0     0.0  0.0   \n",
       "\n",
       "   zua  zucchini  zuke  \n",
       "0  0.0       0.0   0.0  \n",
       "1  0.0       0.0   0.0  \n",
       "2  0.0       0.0   0.0  \n",
       "3  0.0       0.0   0.0  \n",
       "4  0.0       0.0   0.0  \n",
       "\n",
       "[5 rows x 6192 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf=NMF(10,random_state=42,alpha=0.1,l1_ratio=0.5,init='nndsvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=nmf.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps=nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.02351679, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LatentDirichletAllocation(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=lda.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps1=lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "oil cookies olive would product chips buy popcorn problem wait morning wonderful beans dish chili time recommend best good anywhere aroma great almond later powering carrots eating supplier decided medium carb mild alot understand maple hazelnut deal cups hide cost little wont fresh darker additives lime tasted definately cheaper plan brand really waste wine use promo chews postage charged definetly three price complaint case hint holiday flavor notify credit credited another slides loved done caviar longer impressed roast gerber box past wheat intense search coupon super popped tons bowl entire daughters kettle problems bonus ridiculious grocerry details however card convenient\n",
      "\n",
      "Topic #1:\n",
      "good high cherry steaks price value cupcakes smells peppermint italian water ghee gift cents colored purchased convenience albacore foster cereal cheaper minutes smith salad boxes pictured worth kit dr broken sassparilla threw licorice dog bran always done street market soon site tully wide chunks drugs resembles refried low com consistly seemed spicy purchase omaha orer mx expect expected laugh tuna qvc adores finicky disc brewers smaller individual shape ultimate wonders comparison integrity ups picture inside bought best saccharin cold size immune continue get meanwhile person complaints mug town fat fulfiling loves run ha bone breakfast poop sale remained lovers piece\n",
      "\n",
      "Topic #2:\n",
      "br coffee like one good flavor taste tea great love really food would amazon tried product buy cup best price get much also find free drink better store well time bought use make used box even try eat dog found tastes go strong could dogs chocolate flavors sweet sugar favorite stuff order nice since cat got local gluten bad first makes using diet made think day right ordered definitely give rice hot little vanilla sure say bag small want snack loves ever dark natural many purchased something buying thought still old know stores far water cups year bar way keurig\n",
      "\n",
      "Topic #3:\n",
      "br chocolate www href http gp com product amazon tea thank highly great easy popcorn good price recommended free sugar marshmallow terrible like taste cheese white ball find crackers everywhere send buying love always pb worth take mine door way trip night waste mother cheaper low name stash quick locally loved served favorite needs often licorice enough cost heard thins feeling better satisfy happy web granola portion either candies healthy cramps watery light cookie samples affordable looking tennessee work grocery dogs mocha delivered rooibos nutty store sip christmas site fool snack fresh addicted quickly keep baking version found coffee stop\n",
      "\n",
      "Topic #4:\n",
      "great keep english baby meal carry keeps blended bucks love smaller complained example oats addicted snickers smart creme sent lightly original guess better bland lemon oatmeal decafe toffee classic fact good occupied fun cheaper cookies take make relative pepper air crazy taste helps jasmine nectar watery smashed theater overpowering grits mixed spread personally chips agave tasty hours bad option natural milano regular def avail vegetables eating needless toxic options even minutes swedish spreads potential irish season answer tested byproducts loved double tulley inches effective various wants easy coffee flavor hydrating slightly one steak food biscuit crunch ideas size band movie\n",
      "\n",
      "Topic #5:\n",
      "br tea like peanut butter taste good one eat love little tasty flavor bag really time chips fat great healthy product snack much first calories buy sugar made last eating cookie brand salt baby regular natural water teas tried low dog cookies flavors packs breakfast would amazon food box loves pack powder take going stuff potato lot favorite quite perfect find filling best sweet tasted gum use almost still pretty protein guess plastic soup stevia may instead longer cinnamon thought liquid many old want bought chip especially strong think cheaper sure oil light always bit pb small try different mouth\n",
      "\n",
      "Topic #6:\n",
      "good br dog product little highly size price love delicious like morning great recommend glad treat well get use wellness loves bit worth teeth pricey found also dogs one value buy healthy salty perfect still much way peanuts ate package leaves trash help puppy chocolate spicy expensive fantastic salt order take got try really hot broken find bought improved two long tried stash described cook time though shipping enjoyable enjoy stuff enough mix blood sweet something soup surprisingly tin messy shelter mixed days tastes added anymore almonds even giving takes taste subscription best bar helping tea item melt cranberries others\n",
      "\n",
      "Topic #7:\n",
      "loved great available well cups taste decaffeinated morning mustard greenies quickly salmon crisp suckers problems almonds strength packages soon nabob cheerios oats pantry costco choice way product ever boxes crunchy make celtic love never plan discs dressing br like purchase supposed smaller car bananas nothing fish larger cheese number tooth goes coffee keep sweetness bread honey tried anyone regular good run whole scratch expected take sauce medjools half fanatic broke diamond greens recommend picky caff johnny style complement buds placed often rawhide hope tast disc prepare consistency hot blue lollipops taken kenco get gusto sample color fresh seasonings gel guests\n",
      "\n",
      "Topic #8:\n",
      "br like taste good one licorice cereal seems well baby got salt great product seeds eat salty cost mixes delivered convenient problem candy stuck chips jerky find juice little food things better delicious friends butter lemon needs family best wonderful chocolate get treats three cake hard buy newman never always take agar supermarket brewer took hours frontier stevia tell found mix real hazelnut door young used bowl peanut cook almonds kid amazon seed cheerios sweet amount go right expensive type price makes energy chicken test recommended dog two loved tend smells expected friend cups beef whole ones look back drinking\n",
      "\n",
      "Topic #9:\n",
      "bag great treats co love delicious feel stollen value indigestion kona change real scratcher whenever maui father espresso snack occasional raisins discovered loved although every puppy bring botteled training delighted staff candies tulsi apricots favors classic nice trip hmm fill shell kittens bulk everyday consistantly enjoying giving bff sweeteners acai places guilty office problems club cant thankful planters bite soda changed soft delightful soggy judging bites chemicals walks size execellant teaball recover quicker fish touch mile able crackers finding oreos honeymoon smoothie tea looooove like peppered junk wafer search description prior crack freezer haribo mom islands felt idiot outstanding cat\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda,tf_idf,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "like one love taste flavor would tried product buy really little much get best sweet well snack time eat try free stuff make flavors better sugar first tastes think bought use even bag nice salt also made natural used box found chips go something say got bit favorite old good sure ever healthy cookies butter delicious regular way popcorn peanut day give enough lot still water drink since many want however kids right great bad big thought never case find recommend coconut products fruit amazon buying hard quite pack eating feel around without different could gluten far two enjoy low\n",
      "\n",
      "Topic #1:\n",
      "coffee cup strong cups vanilla roast bitter bold starbucks keurig brew coffees flavored drink dark taste french favorite blend one smooth flavor like better medium pods really weak best morning creamer purchase pod use rich tried box go espresso tasting tastes mountain people convenient recommend different bean buy beans maker decaf flavorful ground extra tassimo price aroma brewed green used many delicious pot kona bought aftertaste makes half bland enjoyed grounds work enjoy whole thought timothy overtones daughter full italian make bags disappointed brewing pay sure received pretty even get hazelnut shop caused new every bodied day strength satisfied would\n",
      "\n",
      "Topic #2:\n",
      "br cream received water wait spaghetti milk review mg vanilla box candy powder us sugar got smooth minutes yes fat drink amazon agree others sauce good instead noticed mentioned juice com back liquid energy protein new work put cold check flavors cheese carb whatever http gp www href came mix another even thank receive pop quickly ingredients brewing went size source add wonderful packages cat see wafers careful get red times bone try taste first french easy least supposed seller bit pills sample would brands yum frozen almost read still cholesterol tub nutrition drinks plastic eating strips caffeine promo healthy\n",
      "\n",
      "Topic #3:\n",
      "tea teas drink stash black bag day drinking chai cup peppermint caffeine keurig count english licorice ice flavor smell love hot milk flavorful every mint favorite strong taste herbal bags stores box lover leaves try green spices brew always naturally several organic time much comes rich many yogi water cinnamon boxes loose lemon quality pour iced company sweet brands saving white really carries jasmine home decaffeinated sweetener style add supplier earl fallen also world sugar opinion grey drinkers since flavored spot cream subscribe hits sweeten definitely however makes got favorites worth according excellent disappointed born mum glass bulk sometimes basically\n",
      "\n",
      "Topic #4:\n",
      "food cat cats eat foods baby canned diet chicken organic pet ingredients feeding eats science weight cans vet quality feed years issues angel loves lost open example life put newman two likes wet licking anything back grain better also lots three happy months turkey pounds bowl allergies diarrhea refuses reviews slides bad meals least small seems entree dogs protein expensive salmon eating easy bought pill seem brand keeps fillers subscribe pouch fur meat worked products went dry high point hungry thai health picky wellness healthy dog kittens vegetables lower sprout looks helped old loved halo kd end allergy related away\n",
      "\n",
      "Topic #5:\n",
      "amazon price store local find stores grocery order found stock could locally better product buying always glad purchase pet delivered buy thank cheaper carry son convenience able hard door get love free thanks also keep pack happy even carrying pleasant days shipping know light easy best hight tennessee ordered delivery stash available green nuts money bought beat deal sam quite satisfied club pay tasting bottles compared seem yes went save fast getting online internet carried crackers supply wish com decaffeinated ship quit expensive convenient count plus packs market truly flavor classic cheese boxes exact told lives prices bar peach begged\n",
      "\n",
      "Topic #6:\n",
      "dog treats dogs treat training loves teeth small size puppy get food chicken perfect chew lbs minutes loved bone give love put vet likes help smaller shelter pet also two bag month china seems stopped giving bought using one smell keep pill take allergies quality corn package regular gets biscuit eats comes greenies sure still liver scratching really daily coat broke clean enjoys pills walks foods adores peanut snubbed looooove crazy much carrying duck resembles item tooth cut chews somewhat locally finicky started way ate old went offered quit butter itching newman switching volunteer made look weight fantastic list thing\n",
      "\n",
      "Topic #7:\n",
      "good really rice price taste long use also gift decafe sent powering time well hot carry shipping flavor brown sodium value know enjoyed example product dish definitely expected enough cocoa would everyday beans hummus purchase process texture water dipping received makes gnawing grip convenient yes suprisingly flawed flaxmeal flax flaw flexible flaxseed flay flavoured flies flight flip flavours gogrape flavour fjd fist fit fits five fix fixated fixes fizzy flagyl flavors flair flakes goodlife flattened goodness flavored flavorful flavoring flat flour flock forcibly fool fooled fooling foolish fools goodbye foot force forced forcing floor forehead foreman forever forewarned forget forgot\n",
      "\n",
      "Topic #8:\n",
      "chocolate bar dark hot recommend taste orange melt bars anyone cookie finally sweet excellence lindt cookies order else chewy intense weather filling compares morning likes nothing purebar best cravings candy amazing white protein compare fudge granola mocha definitely also chocolates smooth perfect good world pb top fantastic ever satisfy sugar ones sip savor anything chocoholic cozy despite often covered one highly relaxed relax grahams staple places creme syrup chip expected warm greens short low enough truly main broken stick book comes discs milano package tooth gone sit quickly eat pretty disc compact proce glutun raspberry yeah know texture cereal find\n",
      "\n",
      "Topic #9:\n",
      "great product price taste cups training tasting works giving wonderful purchased value shipping looking delivery expensive fill snack fast lots many morning treats time breakfast free stroller attachable boon years staple pb gift chocoholic self feeders use night busy still swedish spreads sweetness awesome main everyday flavoring flexible flies flight flagyl fjd fizzy flip flock floor flair flat flakes flavors flay flaxseed flaxmeal flax flattened flawed flaw flavor flavored flavours flavorful flavour flavoured flowers floral forever foolish fools foot force forced forcibly forcing forehead foreman forewarned florida forget forgot form formula formulas formulation forth forthwith fortunate fooling fooled fool foods\n"
     ]
    }
   ],
   "source": [
    "print_topics(nmf,tf_idf,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
